{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jupyter Notebook, Step 2 - Identify Features\n",
    "- Build feature selection pipelines using at least three different techniques\n",
    "- **NOTE**: these pipelines are being used for feature selection not prediction\n",
    "    \n",
    "For this portion of the project I will investigate important features in the madelon dataset. \n",
    "\n",
    "One method I will use will be unsupervised learning with a DecisionTreeRegressor against every feature. Second and third, I will use other approaches to attempt to reach the same result as I reach using unsupervised learning, such as SelectKBest and SelectFromModel.\n",
    "\n",
    "For each set of features, I will test the new feature sets against naive models to compare against baseline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "madelon_file ='madelon_train.csv'\n",
    "madelon_data = []        \n",
    "\n",
    "with open(madelon_file) as f:\n",
    "    readcsv = csv.reader(f, delimiter=' ')\n",
    "    \n",
    "    for row in readcsv:\n",
    "        madelon_data.append(row)\n",
    "        \n",
    "madelon_file_target ='madelon_train_targets.csv'\n",
    "madelon_data_target = []        \n",
    "\n",
    "with open(madelon_file_target) as f:\n",
    "    readcsv = csv.reader(f, delimiter=' ')\n",
    "    \n",
    "    for row in readcsv:\n",
    "        madelon_data_target.append(row)\n",
    "        \n",
    "madelon1 = madelon_data[0:200]\n",
    "\n",
    "madelon_data_df = pd.DataFrame(madelon1)\n",
    "madelon_targets_df = pd.DataFrame(madelon_data_target[0:200])\n",
    "\n",
    "X = madelon_data_df\n",
    "y = madelon_targets_df\n",
    "X['y'] = y\n",
    "\n",
    "X = X.drop([500],axis=1)\n",
    "X['y'] = X['y'].map(int)\n",
    "for column in X.columns:\n",
    "    X[column] = X[column].map(int)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "y = X['y']\n",
    "X = X.drop(['y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "def calculate_r_2_for_feature(X, feature, model):\n",
    "    tmp_X = X.drop(feature, axis = 1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(tmp_X, X[feature], test_size=0.25)\n",
    "    \n",
    "    regressor = model()\n",
    "    regressor.fit(X_train, y_train)\n",
    "    \n",
    "    score = regressor.score(X_test, y_test)\n",
    "    return score\n",
    "\n",
    "def mean_r2_for_feature(data, feature, model):\n",
    "    scores = []\n",
    "    for _ in range(100):\n",
    "        scores.append(calculate_r_2_for_feature(data, feature, model))\n",
    "        \n",
    "        scores = np.array(scores)\n",
    "        return scores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores_informative = []\n",
    "for i in range(500):#tqdm(range(500)):\n",
    "    r2 = mean_r2_for_feature(X, i, DecisionTreeRegressor)\n",
    "    if r2 > 0:\n",
    "        scores_informative.append([i,r2])\n",
    "        #print(\"informative found!: \", i, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "information_df = pd.DataFrame(scores_informative)\n",
    "inform_mask = information_df[0]\n",
    "#inform_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_and_score_model_against_raw_and_scaled(model, X_train, X_test, y_train, y_test):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    " \n",
    "    model.fit(X_train, y_train)\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    train_scaled_score = model.score(X_train_scaled, y_train)\n",
    "    test_scaled_score = model.score(X_test_scaled, y_test)\n",
    "    \n",
    "    return {\n",
    "            'model': model,\n",
    "            'train_raw_score' : train_score,\n",
    "            'test_raw_score' : test_score,\n",
    "            'train_scaled_score' : train_scaled_score,\n",
    "            'test_scaled_score' : test_scaled_score,\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inform_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a58ca23a1c54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minform_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'inform_mask' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[inform_mask], y, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>test_raw_score</th>\n",
       "      <th>test_scaled_score</th>\n",
       "      <th>train_raw_score</th>\n",
       "      <th>train_scaled_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.628571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsRegressor(algorithm='auto', leaf_siz...</td>\n",
       "      <td>0.437321</td>\n",
       "      <td>0.331100</td>\n",
       "      <td>0.485099</td>\n",
       "      <td>0.422394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.864286</td>\n",
       "      <td>0.821429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC(C=1.0, cache_size=200, class_weight=None, ...</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.842857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  test_raw_score  \\\n",
       "0  LogisticRegression(C=1.0, class_weight=None, d...        0.683333   \n",
       "1  KNeighborsRegressor(algorithm='auto', leaf_siz...        0.437321   \n",
       "2  KNeighborsClassifier(algorithm='auto', leaf_si...        0.800000   \n",
       "3  DecisionTreeClassifier(class_weight=None, crit...        0.700000   \n",
       "4  SVC(C=1.0, cache_size=200, class_weight=None, ...        0.633333   \n",
       "\n",
       "   test_scaled_score  train_raw_score  train_scaled_score  \n",
       "0           0.666667         0.678571            0.628571  \n",
       "1           0.331100         0.485099            0.422394  \n",
       "2           0.750000         0.864286            0.821429  \n",
       "3           0.683333         1.000000            1.000000  \n",
       "4           0.866667         1.000000            0.842857  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "results = [fit_and_score_model_against_raw_and_scaled(LogisticRegression(), X_train, X_test, y_train, y_test),\n",
    "           fit_and_score_model_against_raw_and_scaled(KNeighborsRegressor(), X_train, X_test, y_train, y_test),\n",
    "           fit_and_score_model_against_raw_and_scaled(KNeighborsClassifier(), X_train, X_test, y_train, y_test),\n",
    "           fit_and_score_model_against_raw_and_scaled(DecisionTreeClassifier(), X_train, X_test, y_train, y_test),\n",
    "           fit_and_score_model_against_raw_and_scaled(SVC(), X_train, X_test, y_train, y_test)]\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised learning methods clearly enhance the ability of the models to predict for the dataset. Even with the very small dataset, the model now performs noticably better. \n",
    "\n",
    "Next I will use SelectFromModel and SelectKBest to choose features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, \\\n",
    "                                      SelectFromModel, \\\n",
    "                                      RFE, SelectPercentile\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 500)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k=20, score_func=<function f_classif at 0x7f6ce0d75268>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skb = SelectKBest(k=20)\n",
    "\n",
    "skb.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skb_feats = np.where(skb.get_support())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 32,  34,  40,  47,  48,  70, 105, 128, 193, 235, 282, 378, 380,\n",
       "       402, 415, 417, 420, 435, 474, 477])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skb_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skb_feats.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skb.pvalues_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[skb_feats], y, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 20)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>test_raw_score</th>\n",
       "      <th>test_scaled_score</th>\n",
       "      <th>train_raw_score</th>\n",
       "      <th>train_scaled_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsRegressor(algorithm='auto', leaf_siz...</td>\n",
       "      <td>-0.125359</td>\n",
       "      <td>-0.122488</td>\n",
       "      <td>0.259604</td>\n",
       "      <td>0.270457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC(C=1.0, cache_size=200, class_weight=None, ...</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.885714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  test_raw_score  \\\n",
       "0  LogisticRegression(C=1.0, class_weight=None, d...        0.633333   \n",
       "1  KNeighborsRegressor(algorithm='auto', leaf_siz...       -0.125359   \n",
       "2  KNeighborsClassifier(algorithm='auto', leaf_si...        0.566667   \n",
       "3  DecisionTreeClassifier(class_weight=None, crit...        0.583333   \n",
       "4  SVC(C=1.0, cache_size=200, class_weight=None, ...        0.633333   \n",
       "\n",
       "   test_scaled_score  train_raw_score  train_scaled_score  \n",
       "0           0.716667         0.735714            0.714286  \n",
       "1          -0.122488         0.259604            0.270457  \n",
       "2           0.583333         0.700000            0.757143  \n",
       "3           0.600000         1.000000            1.000000  \n",
       "4           0.733333         1.000000            0.885714  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = [fit_and_score_model_against_raw_and_scaled(LogisticRegression(), X_train, X_test, y_train, y_test),\n",
    "           fit_and_score_model_against_raw_and_scaled(KNeighborsRegressor(), X_train, X_test, y_train, y_test),\n",
    "           fit_and_score_model_against_raw_and_scaled(KNeighborsClassifier(), X_train, X_test, y_train, y_test),\n",
    "           fit_and_score_model_against_raw_and_scaled(DecisionTreeClassifier(), X_train, X_test, y_train, y_test),\n",
    "           fit_and_score_model_against_raw_and_scaled(SVC(), X_train, X_test, y_train, y_test)]\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SelectKBest clearly under performs unsupervised learning when selecting 20 best features. \n",
    "\n",
    "A notable exception is LogisticRegression, which actually shows signs of doing slightly better. It should be noted, however, that different train test splits were used in these two datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the third feature selection mechanism, I will use SelectFromModel with a Support Vector Machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)\n",
    "\n",
    "sfm = SelectFromModel(LogisticRegression(), threshold='2*mean')\n",
    "sfm.fit(X_train_scaled, y_train)\n",
    "sfm_feats = np.where(sfm.get_support())[0]\n",
    "#sfm_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfm_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>test_raw_score</th>\n",
       "      <th>test_scaled_score</th>\n",
       "      <th>train_raw_score</th>\n",
       "      <th>train_scaled_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsRegressor(algorithm='auto', leaf_siz...</td>\n",
       "      <td>-0.234450</td>\n",
       "      <td>-0.168421</td>\n",
       "      <td>0.498363</td>\n",
       "      <td>0.514040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.878571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC(C=1.0, cache_size=200, class_weight=None, ...</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  test_raw_score  \\\n",
       "0  LogisticRegression(C=1.0, class_weight=None, d...        0.550000   \n",
       "1  KNeighborsRegressor(algorithm='auto', leaf_siz...       -0.234450   \n",
       "2  KNeighborsClassifier(algorithm='auto', leaf_si...        0.550000   \n",
       "3  DecisionTreeClassifier(class_weight=None, crit...        0.500000   \n",
       "4  SVC(C=1.0, cache_size=200, class_weight=None, ...        0.633333   \n",
       "\n",
       "   test_scaled_score  train_raw_score  train_scaled_score  \n",
       "0           0.533333         1.000000            1.000000  \n",
       "1          -0.168421         0.498363            0.514040  \n",
       "2           0.600000         0.871429            0.878571  \n",
       "3           0.466667         1.000000            1.000000  \n",
       "4           0.583333         1.000000            1.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[sfm_feats], y, test_size=.3, random_state=42)\n",
    "\n",
    "results = [fit_and_score_model_against_raw_and_scaled(LogisticRegression(), X_train, X_test, y_train, y_test),\n",
    "           fit_and_score_model_against_raw_and_scaled(KNeighborsRegressor(), X_train, X_test, y_train, y_test),\n",
    "           fit_and_score_model_against_raw_and_scaled(KNeighborsClassifier(), X_train, X_test, y_train, y_test),\n",
    "           fit_and_score_model_against_raw_and_scaled(DecisionTreeClassifier(), X_train, X_test, y_train, y_test),\n",
    "           fit_and_score_model_against_raw_and_scaled(SVC(), X_train, X_test, y_train, y_test)]\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select from model does not clearly show any improvement on the naive models at this point. After doing some tuning to the selection mechanism (threshold), I still do not see any marked improvement at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "supports = [inform_mask,skb_feats,sfm_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0      28\n",
       " 1      48\n",
       " 2      64\n",
       " 3     105\n",
       " 4     128\n",
       " 5     153\n",
       " 6     241\n",
       " 7     281\n",
       " 8     318\n",
       " 9     336\n",
       " 10    338\n",
       " 11    378\n",
       " 12    433\n",
       " 13    442\n",
       " 14    451\n",
       " 15    453\n",
       " 16    455\n",
       " 17    472\n",
       " 18    475\n",
       " 19    493\n",
       " Name: 0, dtype: int64,\n",
       " array([ 32,  34,  40,  47,  48,  70, 105, 128, 193, 235, 282, 378, 380,\n",
       "        402, 415, 417, 420, 435, 474, 477]),\n",
       " array([  1,  32,  34,  40,  43,  47,  51,  55,  70,  73,  75,  80,  83,\n",
       "         85,  93, 111, 126, 131, 141, 155, 162, 192, 193, 196, 200, 207,\n",
       "        209, 213, 218, 231, 287, 295, 299, 306, 376, 387, 389, 395, 407,\n",
       "        415, 417, 418, 420, 424, 430, 435, 441, 452, 461, 463, 473, 476])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('supports.pkl', 'wb') as f:\n",
    "    pickle.dump(supports, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "madelon_from_sql = pd.read_pickle('m_sql_1.pickle')\n",
    "madelon_from_sql.set_index('_id', inplace=True)\n",
    "X = madelon_from_sql.drop('target', axis=1)\n",
    "y = madelon_from_sql['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 1000), (2000,))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xb = X[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xb = Xb[['feat_257',\n",
    " 'feat_269',\n",
    " 'feat_308',\n",
    " 'feat_315',\n",
    " 'feat_336',\n",
    " 'feat_341',\n",
    " 'feat_395',\n",
    " 'feat_504',\n",
    " 'feat_526',\n",
    " 'feat_639',\n",
    " 'feat_681',\n",
    " 'feat_701',\n",
    " 'feat_724',\n",
    " 'feat_736',\n",
    " 'feat_769',\n",
    " 'feat_808',\n",
    " 'feat_829',\n",
    " 'feat_867',\n",
    " 'feat_920',\n",
    " 'feat_956']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 1/1000 [00:00<11:47,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/1000 [00:01<11:41,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 3/1000 [00:02<11:29,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 4/1000 [00:02<11:36,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 5/1000 [00:03<11:24,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 6/1000 [00:04<11:54,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 7/1000 [00:04<11:46,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 8/1000 [00:05<11:45,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 9/1000 [00:06<12:08,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 10/1000 [00:07<11:58,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 11/1000 [00:07<11:58,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 12/1000 [00:08<11:53,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 13/1000 [00:09<11:46,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 14/1000 [00:09<11:41,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 15/1000 [00:10<11:41,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 16/1000 [00:11<11:36,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 17/1000 [00:11<11:31,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 18/1000 [00:12<11:24,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 19/1000 [00:13<11:21,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 20/1000 [00:13<11:17,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 21/1000 [00:14<11:17,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 22/1000 [00:15<11:14,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 23/1000 [00:15<11:14,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 24/1000 [00:16<11:18,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▎         | 25/1000 [00:17<11:16,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 26/1000 [00:18<11:15,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 27/1000 [00:18<11:13,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 28/1000 [00:19<11:11,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 29/1000 [00:20<11:16,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 30/1000 [00:20<11:14,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 31/1000 [00:21<11:15,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 32/1000 [00:22<11:12,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 33/1000 [00:23<11:18,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 34/1000 [00:23<11:16,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 35/1000 [00:24<11:13,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 36/1000 [00:25<11:14,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 37/1000 [00:25<11:10,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 38/1000 [00:26<11:08,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 39/1000 [00:26<11:05,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 40/1000 [00:27<11:08,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 41/1000 [00:28<11:06,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 42/1000 [00:29<11:06,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lots of stuff\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-c6e0978bc33b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"lots of stuff\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_r2_for_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDecisionTreeRegressor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mr2\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.92\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msql_scores_informative\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-88fc224234ce>\u001b[0m in \u001b[0;36mmean_r2_for_feature\u001b[0;34m(data, feature, model)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_r_2_for_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-88fc224234ce>\u001b[0m in \u001b[0;36mcalculate_r_2_for_feature\u001b[0;34m(X, feature, model)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mregressor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1030\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    348\u001b[0m                                            self.min_impurity_split)\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sql_scores_informative = []\n",
    "for i in tqdm(Xb):\n",
    "    print(\"lots of stuff\")\n",
    "    r2 = mean_r2_for_feature(Xb, i, DecisionTreeRegressor)\n",
    "    if r2 > 0.92:\n",
    "        sql_scores_informative.append([i,r2])\n",
    "        print(\"informative found!: \", i, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['feat_269', 0.94191582689721287],\n",
       " ['feat_315', 0.93182798428292213],\n",
       " ['feat_341', 0.93280868233103176],\n",
       " ['feat_395', 0.93785116449378292],\n",
       " ['feat_639', 0.97685423340934086],\n",
       " ['feat_956', 0.97528427979255861]]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_scores_informative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['feat_257', 0.74895256045322978],\n",
       " ['feat_269', 0.88810281325383411],\n",
       " ['feat_681', 0.67880996399072724],\n",
       " ['feat_808', 0.69855498767387192],\n",
       " ['feat_829', 0.70962933432153519],\n",
       " ['feat_920', 0.81468393371269088]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_scores_informative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['feat_257', 0.48885988681021347],\n",
       " ['feat_269', 0.55368127493783093],\n",
       " ['feat_308', 0.31454295404360233],\n",
       " ['feat_315', 0.73546577604917074],\n",
       " ['feat_336', 0.69337820342894474],\n",
       " ['feat_341', 0.62144839816190611],\n",
       " ['feat_395', 0.63479630273013954],\n",
       " ['feat_504', 0.40896058230504628],\n",
       " ['feat_526', 0.21032540438036473],\n",
       " ['feat_639', 0.84227343387442299],\n",
       " ['feat_681', 0.47442578506922012],\n",
       " ['feat_701', 0.76280481035288283],\n",
       " ['feat_724', 0.52833368594341357],\n",
       " ['feat_736', 0.60555953875298307],\n",
       " ['feat_769', 0.43235716767371635],\n",
       " ['feat_808', 0.47998839978887853],\n",
       " ['feat_829', 0.58253418729726647],\n",
       " ['feat_867', 0.63503139250910301],\n",
       " ['feat_920', 0.64267634615223335],\n",
       " ['feat_956', 0.93082504050825332]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_scores_informative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sql_scores_informative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('supports_sql.pkl', 'wb') as f:\n",
    "    pickle.dump(sql_scores_informative, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
