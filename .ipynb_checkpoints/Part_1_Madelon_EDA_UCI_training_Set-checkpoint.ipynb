{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "madelon_file ='madelon_train.csv'\n",
    "madelon_data = []        \n",
    "\n",
    "with open(madelon_file) as f:\n",
    "    readcsv = csv.reader(f, delimiter=' ')\n",
    "    \n",
    "    for row in readcsv:\n",
    "        madelon_data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "madelon_file_target ='madelon_train_targets.csv'\n",
    "madelon_data_target = []        \n",
    "\n",
    "with open(madelon_file_target) as f:\n",
    "    readcsv = csv.reader(f, delimiter=' ')\n",
    "    \n",
    "    for row in readcsv:\n",
    "        madelon_data_target.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sample 10% of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#madelon_data[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "madelon_data_df = pd.DataFrame(madelon_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "madelon_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "madelon_targets_df = pd.DataFrame(madelon_data_target)\n",
    "madelon_targets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = madelon_data_df\n",
    "y = madelon_targets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X.iloc[:,0],X.iloc[:,1],c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,4))\n",
    "fig.add_subplot(2,4,1)\n",
    "plt.scatter(X.iloc[:,0],X.iloc[:,1], c=y)\n",
    "fig.add_subplot(2,4,2)\n",
    "plt.scatter(X.iloc[:,0],X.iloc[:,2], c=y)\n",
    "fig.add_subplot(2,4,3)\n",
    "plt.scatter(X.iloc[:,0],X.iloc[:,3], c=y)\n",
    "fig.add_subplot(2,4,4)\n",
    "plt.scatter(X.iloc[:,1],X.iloc[:,2], c=y)\n",
    "fig.add_subplot(2,4,5)\n",
    "plt.scatter(X.iloc[:,1],X.iloc[:,3], c=y)\n",
    "fig.add_subplot(2,4,6)\n",
    "plt.scatter(X.iloc[:,1],X.iloc[:,4], c=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unforuntately, there are 249,500 different combinations of columns available to plot on scatter plots. Typically, scatter plots are a useful metric, but in this case would take far to much memory and time to parse through. (500 * 499)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop([500],axis=1)\n",
    "X['y'] = X['y'].map(int)\n",
    "for column in X.columns:\n",
    "    X[column] = X[column].map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_corr = X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_corr.sort_values('y', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jupyter Notebook, Step 1 - Benchmarking\n",
    "- build pipeline to perform a naive fit for each of the base model classes:\n",
    "\t- logistic regression\n",
    "\t- decision tree\n",
    "\t- k nearest neighbors\n",
    "\t- support vector classifier\n",
    "- in order to do this, you will need to set a high `C` value in order to perform minimal regularization, in the case of logistic regression and support vector classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = X['y']\n",
    "X = X.drop(['y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_and_score_model_against_raw_and_scaled(model, X_train, X_test, y_train, y_test):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    " \n",
    "    model.fit(X_train, y_train)\n",
    "    train_score = model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    train_scaled_score = model.score(X_train_scaled, y_train)\n",
    "    test_scaled_score = model.score(X_test_scaled, y_test)\n",
    "    \n",
    "    return {\n",
    "            'model': model,\n",
    "            'train_raw_score' : train_score,\n",
    "            'test_raw_score' : test_score,\n",
    "            'train_scaled_score' : train_scaled_score,\n",
    "            'test_scaled_score' : test_scaled_score,\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = [fit_and_score_model_against_raw_and_scaled(LogisticRegression(), X_train, X_test, y_train, y_test),\n",
    "       fit_and_score_model_against_raw_and_scaled(KNeighborsRegressor(), X_train, X_test, y_train, y_test)]\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import SelectFromModel, SelectKBest, f_regression\n",
    "# transformer_pipe = make_pipeline(SelectKBest(score_func=f_regression, k=50),\n",
    "#                                  StandardScaler(),\n",
    "#                                  SelectFromModel(LogisticRegression()))\n",
    "# transformer_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_skb_scaled_sfm = transformer_pipe.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_skb_scaled_sfm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer_pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(features_skb_scaled_sfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.corr().sort_values('y', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = LogisticRegression()\n",
    "# lr.fit(features_skb_scaled_sfm, y_train)\n",
    "# lr.score(features_skb_scaled_sfm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "def calculate_r_2_for_feature(X, feature, model):\n",
    "    tmp_X = X.drop(feature, axis = 1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(tmp_X, X[feature], test_size=0.25)\n",
    "    \n",
    "    regressor = model()\n",
    "    regressor.fit(X_train, y_train)\n",
    "    \n",
    "    score = regressor.score(X_test, y_test)\n",
    "    return score\n",
    "\n",
    "def mean_r2_for_feature(data, feature, model):\n",
    "    scores = []\n",
    "    for _ in range(100):\n",
    "        scores.append(calculate_r_2_for_feature(data, feature, model))\n",
    "        \n",
    "        scores = np.array(scores)\n",
    "        return scores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_informative = []\n",
    "for i in tqdm(range(500)):\n",
    "    r2 = mean_r2_for_feature(X, i, DecisionTreeRegressor)\n",
    "#     if i % 10 == 0:\n",
    "#         print('processing')\n",
    "    if r2 > 0:\n",
    "        scores_informative.append(r2)\n",
    "        print(\"informative found!: \", i, r2)\n",
    "    #print(i, mean_r2_for_feature(X, i, DecisionTreeRegressor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_informative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
